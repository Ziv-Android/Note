## 音视频基础知识
### 声音的物理性质
声音是有物体振动产生的。物体振动会引起周围空气产生疏密变化，形成疏密相间的纵波，由此产生了声波，声波现象一直会延续到震动消失为止。

声波的三要素：
1. 频率：代表音阶的高低。频率越低，波长越长，越容易绕开障碍物，能量衰减越小，声音传播越远。
2. 振幅：代表响度。能量大小的反映，测量单位--分贝。
3. 波形：代表音色。不同材质的物体震动产生的声波的形状不同，波形表示了能发出什么样的声音。

人耳听力范围：20Hz-20kHz，尤其对3-4k频率范围内的声音比较敏感。频率范围较宽的音乐，其声压在80-90dB为最佳，超过90dB损伤人耳，105dB为人耳极限

声音在不同的传播介质中声速不同，空气：340m/s，蒸馏水：1497m/s，铁棒：5200m/s（真空不存在传播介质，因此声音在真空中是无法传播的）

吸音：解决声音反射而产生的嘈杂感。吸音材料可以衰减射音源的反射能量，从而达到对原有声源的保真效果。录音棚
隔音：解决声音的透射而降低主体空间内的吵闹感。隔音材料可以衰减射音源的透射能量，从而达到主体空间的安静状态。KTV

回声（echo）：声音在传播过程中遇到障碍物被反弹回来，被我们再次听到。当两次声音间隔小于80ms则无法再分辨出回声与原声。

共鸣：声音的传播过程是一种能量的传播过程的表现就是共鸣。当两个频率相近的物体，当其中一个物体处于振动发声的状态时，另一个物体也会随之震动。

### 数字音频
1. 采样：在时间轴上对信号进行数字化。根据奈奎斯特定理（采样定理）--按比声音最高频率高2倍以上的频率对声音进行采样（也称AD转换）就可以保证声音质量不会被降低。根据人耳可以听到的频率范围，采样频率一般为44.1kHz，表示每秒采样44100次。  
2. 量化：在幅度上对信号进行数字化。16比特(2字节)的二进制表示的范围[-32768, 32767]，共65536个幅度值。  
3. 编码：按照一定的格式记录采样和量化后的数字数据。音频的裸数据格式为PCM(Pulse Code Modulation)脉冲编码调制数据，描述一段PCM数据一般需要量化格式(sampleFormat)、采样率(sampleRate)、声道数(channel)。如CD音质，量化格式(位深度)16比特，采样率44100，声道数2。  

数据比特率：用于描述声音格式大小，数据比特率(kbps)=采样率\*量化格式\*声道数， 存储空间(MB)=数据比特率\*时间(s)/8/1024  

分贝(dB)：用来描述声音强度的单位，无量纲。N=10\*lg(A1/A0)：A0-基准值(参考值)，A1-被度量值

### 音频编码
无损压缩是指解压后的数据可以完全恢复

压缩编码的原理是去除冗余信息，即去除人耳可感知范围之外的音频信号和被掩蔽掉的音频信号。人耳的掩蔽效应主要表现为**频域掩蔽效应**和**时域掩蔽效应**。

常见的压缩编码格式
编码格式 | 描述 | 特点 | 适用场景 
--- | --- | --- | ---
WAV | PCM数据+44字节的采样率、声道数、数据格式等描述信息 | 音质非常好，大多数软件都支持 | 多媒体开发的中间文件、保存音乐和音效素材
MP3 | 较好的压缩比，1:10甚至1:12的压缩率，使用LAME编码的MP3文件听感上非常接近WAV文件 | 音质在128Kbit/s以上表现良好，压缩比较高，大量软件和硬件都支持，兼容性好 | 高比特率下对兼容新有要求的音乐欣赏
AAC | 音频有损压缩技术，主要有LC-ACC传统ACC主要应用于中高码率场景(大于80Kbit/s)的编码，HE-ACC(AAC+SBR)主要用于中低码率场景(小于80Kbit/s)，HE-ACC v2(AAC+SBR+PS)应用于低码率场景(小于48Kbit/s) | 在小于128Kbit/s的码率下表现优异 | 多用于视频中的音频编码
Ogg | **免费**在各种码率下都有不错的表现，尤其是中低码率场景。但目前媒体服务软件支持较低。 | 以更低的码率呈现更高的音质，高中低码率下均有良好表现，兼容性较差，流媒体特性不支持 | 语音聊天的音频消息场景
AC3 | 有损编码，广泛用于5.1声道（5个全频域和1个超低音声道组成） | 384-448kb/s码率应用于激光唱片和DVD，640kb/s应用于电影院 | 

音频帧（与编码格式相关）
PCM没有音频帧的概念，根据采样率和采样精度就可以播放
AMR帧：规定每20ms的音频为1帧，每帧之间相互独立，可采用不同的编码算法和编码参数
MP3帧：由文件大小和帧长决定，每一帧长度可不固定，也可固定，由比特率决定，每一帧分为帧头和数据实体两部分，帧头记录MP3的比特率、采样率、版本等信息，每帧之间相互独立。

声道：声音在录制或播放时在不同空间位置或回放的相互独立的音频信号，所以声道数也就是声音录制时的姻缘数量会回放时的扬声器数量。单声道，立体声道（双声道，左右对称的两个），4声道（前左，前右，后左，后右），4.1声道（相比4声道增加一个低音音箱），5.1声道（左环绕，左声道，中置，低音炮，右声道，右环绕），7.1声道（相比5.1增加后置环绕左，后置环绕右）

### 图像的物理特性
光的三原色：红R、绿G、蓝B

图像的RGB数值表示：
浮点数表示(0.0~1.0)：OpenGL ES中使用的表达方式  
整数表示(0~255)：8个比特表示一个子像素，32个比特表示一个像素RGBA_8888，Android平台上的RGB_565为16比特表示一个像素

位图bitmap所占内存大小计算方式：屏幕分辨率\*一个像素所占空间大小，如1280\*720的RGBA_8888的bitmap所占空间大小为1280\*720\*4=3.1516MB

图像的YUV数值表示：
YUV主要应用于优化彩色视频信号传输，向后兼容老式黑白电视，黑白电视只接收处理Y信号分量。YUV最大的优点在于只需要占用极少的频宽，而RGB需要三个独立的视频信号独立传输。  
Y：亮度（Luma或Luminance），也称灰阶值，将RGB信号的特定部分叠加在一起。  
UV：色差，U和V是构成颜色的两个分量，色度，饱和度（Chroma或Chrominace），描述影像的色调Cr与饱和度Cb，Cr反映了RBG输入信号红色部分与RGB信号亮度之间的差异，Cb反映了RBG输入信号蓝色部分与RGB信号亮度之间的差异

YUV各占一个字节，即0-255，但实际为了防止信号过载，Y的取值范围：16-235，UV的取值范围：16-240  
YUV最常用的采样格式是4:2:0，这不是说只有Y，Cb分量没有Cr分量，而是指对每行扫描线来说，只有一种色度分量是以2:1的抽样率来存储的相邻的扫描行存储着不同的色度分量 **？**

RGB与YUV之间的转换
转换格式 | 转换矩阵
--- | ---
YUV -> RGB | 常规：![常规转换标准](pic/YUV-RGB%E5%B8%B8%E8%A7%84%E8%BD%AC%E6%8D%A2%E7%9F%A9%E9%98%B5.png) <p>标清BT.601：![标清BT.601标准](pic/YUV-RGB-SD-TV%E8%BD%AC%E6%8D%A2%E7%9F%A9%E9%98%B5.png)<p>高清BT.709：![高清BT.709标准](pic/YUV-RGB-HD-TV%E8%BD%AC%E6%8D%A2%E7%9F%A9%E9%98%B5.png)
RGB -> YUV | 常规：![常规转换标准](pic/RGB-YUV%E5%B8%B8%E8%A7%84%E8%BD%AC%E6%8D%A2%E7%9F%A9%E9%98%B5.png) <p>标清BT.601：![标清BT.601标准](pic/RGB-YUV-SD-TV%E8%BD%AC%E6%8D%A2%E7%9F%A9%E9%98%B5.png)<p> 高清BT.709：![高清BT.709标准](pic/RGB-YUV-HD-TV%E8%BD%AC%E6%8D%A2%E7%9F%A9%E9%98%B5.png)

iOS的摄像头采集出一帧数据后（CMSampleBufferRef），需要调用CVBufferGetAttachment来获取YCbCrMatrix来决定使用那个矩阵进行转换，Android的摄像头直接使用纹理ID的回调，不涉及矩阵选择的问题

### 视频的编码方式
视频编码：使用帧内编码+帧间编码技术去除视频中大量的冗余信息  
运动补偿-通过先前的局部图像来预测、补偿当前的局部图像，他是减少帧序列冗余信息的有效方法  
运动表示-不同区域的图像需要使用不同的运动矢量来描述运动信息  
运动估计-从视频序列中抽取运动信息的一整套技术  

ISO制定的MPEG视频压缩标准与ITU-T制定的H.26x系列视频编码标准

封装格式
把编码后的音视频数据以一定的格式封装到一个容器中，常见的封装格式有MKV，AVI，TS等

编码概念  
帧率：用于测量显示帧数的量度，测量单位每秒显示帧数(fps)，30fps对应流畅，60fps逼真，超过75fps或高过显示器屏幕刷新频率则无明显提升，性能浪费  

刷新率：屏幕每秒刷新次数，分为垂直刷新率和水平刷新率，一般指垂直刷新率，以赫兹(Hz)为单位，刷新率越高图像越稳定清晰自然，80Hz以上的刷新率可完全消除图像闪烁和抖动感

画质与码率
码率也叫比特率，比特率越高带宽消耗越大，与文件大小息息相关，画质与码率没有直接关系。

IPB帧  
I(intra picture)帧内编码帧，通常是每个GOP的第一帧，作为随机访问的参考点，自身去除视频的空间冗余信息，能独立解码出一帧完整的视频画面，压缩率为7  
P(predictive-frame)前向预测编码帧，通过将图像序列中前面已编码帧的时间冗余信息充分去除来压缩传输数据量的编码图像，也称预测帧，需要参考前一个I帧或P帧才能解码出视频画面，压缩率为20  
B(bi-directional interpolated prediction frame)双向预测内插编码帧，即考虑原图像序列前面的已编码帧，又顾及源图像序列后面的已编码帧之间的时间冗余信息来压缩传输数据量的编码图像，也称双向预测帧，需要前一个I或P帧以及后一个P帧才能解码出完整视频画面，压缩率50，但解码B帧时，CPU资源消耗最大  

IDR帧与I帧的理解：因为H.264采用多帧预测，所以I帧之后的P帧有可能参考I帧之前的帧，这使得在随机访问下不能以找到I帧作为参考条件，因为即使找到I帧，之后的视频画面也有可能解码不出来，因此引入特殊的I帧--IDR帧，IDR帧之后的所有参考帧只能参考到该IDR帧，在解码器中，一旦接收到IDR帧，就会立即清理参考缓冲区，并将IDR帧作为被参考的帧。

PTS与DTS
DTS(Decoding Time Stamp)主要用于视频解码，AVPacket中的一个成员，表示读入内存的比特流什么时候送入解码器进行解码
PTS(Presentation Time Stamp)主要用于视频在解码阶段进行视频的同步和输出，AVFrame中一个参数，决定解码后的视频帧什么时候显示出来

FFmpeg中使用AVPacket结构体描述解码前或编码后的压缩数据，使用AVFrame结构体描述解码后或编码前的原始数据，在没有B帧存在的条件下，DTS与PTS的输出顺序是一致的。

GOP：两个I帧之间形成的一组帧数据，gop_size代表两个I帧之间的间隔，gop_size越大，画面质量越高 **？**

## 开发工具配置


## MediaPlayer与MediaPlayerService


## AwesonePlayer与NuPlayer


## OpenMAX（OMX）框架与OpenSL、OpenGL


## FFmpeg项目


## 视频编码与格式分析


## 直播技术
